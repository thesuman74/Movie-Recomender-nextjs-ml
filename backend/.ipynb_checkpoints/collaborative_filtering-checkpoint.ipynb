{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a MovieLens Recommender System\n",
    "\n",
    "<img src=\"images/movielens.png\" width='25%' align='right'/>\n",
    "\n",
    "Want to know how Spotify, Amazon, and Netflix generate recommendations for their users? In this tutorial, we will explore two types of recommender systems: 1) collaborative filtering, and 2) content-based filtering. We will build our own recommendation system using the [MovieLens](https://movielens.org/home) dataset in Python.\n",
    "\n",
    "### What is MovieLens?\n",
    "\n",
    "MovieLens is a recommender system that was developed by GroupLens, a computer science research lab at the University of Minnesota. It recommends movies to its users based on their movie ratings. It is also a dataset that is widely used in research and teaching contexts. \n",
    "\n",
    "### Tutorial Outline\n",
    "\n",
    "This tutorial is broken down into 7 steps:\n",
    "\n",
    "1. Importing the dependnecies\n",
    "1. Loading the data\n",
    "1. Exploratory data analysis \n",
    "1. Data pre-processing\n",
    "1. Collaborative filtering using k-Nearest Neighbors\n",
    "1. Handling the cold-start problem with content-based filtering \n",
    "1. Dimensionality reduction with matrix factorization\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Import Dependencies\n",
    "\n",
    "We are using [pandas.DataFrame](http://pandas.pydata.org/pandas-docs/version/0.19/generated/pandas.DataFrame.html) to represent our data. We will visualize our data with [matplotlib](https://matplotlib.org/) and [seaborn](https://seaborn.pydata.org/).\n",
    "\n",
    "**What is a DataFrame?**\n",
    "\n",
    "- a two-dimensional Pandas data structure\n",
    "- columns represent features, rows represent items\n",
    "- analogous to an Excel spreadsheet or SQL table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's download a small version of the MovieLens dataset. You can download the data [here](https://grouplens.org/datasets/movielens/). \n",
    "\n",
    "<img src=\"images/download_movielens.png\" width='40%'/>\n",
    "\n",
    "\n",
    "We're working with data in `ml-latest-small.zip` and will need to add the following files to our repository:\n",
    "\n",
    "- ratings.csv\n",
    "- movies.csv\n",
    "\n",
    "Alternatively, you can access the data here:\n",
    "\n",
    "- https://s3-us-west-2.amazonaws.com/recommender-tutorial/movies.csv\n",
    "- https://s3-us-west-2.amazonaws.com/recommender-tutorial/ratings.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv('https://s3-us-west-2.amazonaws.com/recommender-tutorial/ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv('https://s3-us-west-2.amazonaws.com/recommender-tutorial/movies.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_ratings = len(ratings)\n",
    "n_movies = ratings['movieId'].nunique()\n",
    "n_users = ratings['userId'].nunique()\n",
    "\n",
    "print(f\"Number of ratings: {n_ratings}\")\n",
    "print(f\"Number of unique movieId's: {n_movies}\")\n",
    "print(f\"Number of unique users: {n_users}\")\n",
    "print(f\"Average number of ratings per user: {round(n_ratings/n_users, 2)}\")\n",
    "print(f\"Average number of ratings per movie: {round(n_ratings/n_movies, 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Glimpse at Movie Genres\n",
    "\n",
    "The movies dataset needs to be cleaned in two ways:\n",
    "\n",
    "- `genres` is expressed as a string with a pipe `|` separating each genre. We will manipulate this string into a list, which will make it much easier to analyze.\n",
    "- `title` currently has (year) appended at the end. We will extract year from each title string and create a new column for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['genres'] = movies['genres'].apply(lambda x: x.split(\"|\"))\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How many movie genres are there?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "genre_frequency = Counter(g for genres in movies['genres'] for g in genres)\n",
    "\n",
    "print(f\"There are {len(genre_frequency)} genres.\")\n",
    "\n",
    "genre_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The 5 most common genres: \\n\", genre_frequency.most_common(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Data Pre-processing\n",
    "\n",
    "We are going to use a technique called colaborative filtering to generate recommendations for users. This technique is based on the premise that similar people like similar things. \n",
    "\n",
    "The first step is to transform our data into a user-item matrix, also known as a \"utility\" matrix. In this matrix, rows represent users and columns represent movies. The beauty of collaborative filtering is that it doesn't require any information about the users or the movies user to generate recommendations.\n",
    "\n",
    "<img src=\"images/user_movie_matrix.png\" width=50%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `create_X()` function outputs a sparse matrix $X$ with four mapper dictionaries:\n",
    "\n",
    "- **user_mapper**: maps user id to user index\n",
    "- **movie_mapper**: maps movie id to movie index\n",
    "- **user_inv_mapper**: maps user index to user id\n",
    "- **movie_inv_mapper**: maps movie index to movie id\n",
    "\n",
    "We need these dictionaries because they map which row/column of the utility matrix corresponds to which user/movie id.\n",
    "\n",
    "Our $X$ (user-item) matrix is a [scipy.sparse.csr_matrix](https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.sparse.csr_matrix.html) which stores the data sparsely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "def create_X(df):\n",
    "    \"\"\"\n",
    "    Generates a sparse matrix from ratings dataframe.\n",
    "    \n",
    "    Args:\n",
    "        df: pandas dataframe containing 3 columns (userId, movieId, rating)\n",
    "    \n",
    "    Returns:\n",
    "        X: sparse matrix\n",
    "        user_mapper: dict that maps user id's to user indices\n",
    "        user_inv_mapper: dict that maps user indices to user id's\n",
    "        movie_mapper: dict that maps movie id's to movie indices\n",
    "        movie_inv_mapper: dict that maps movie indices to movie id's\n",
    "    \"\"\"\n",
    "    M = df['userId'].nunique()\n",
    "    N = df['movieId'].nunique()\n",
    "\n",
    "    user_mapper = dict(zip(np.unique(df[\"userId\"]), list(range(M))))\n",
    "    movie_mapper = dict(zip(np.unique(df[\"movieId\"]), list(range(N))))\n",
    "    \n",
    "    user_inv_mapper = dict(zip(list(range(M)), np.unique(df[\"userId\"])))\n",
    "    movie_inv_mapper = dict(zip(list(range(N)), np.unique(df[\"movieId\"])))\n",
    "    \n",
    "    user_index = [user_mapper[i] for i in df['userId']]\n",
    "    item_index = [movie_mapper[i] for i in df['movieId']]\n",
    "\n",
    "    X = csr_matrix((df[\"rating\"], (user_index,item_index)), shape=(M,N))\n",
    "    \n",
    "    return X, user_mapper, movie_mapper, user_inv_mapper, movie_inv_mapper\n",
    "\n",
    "X, user_mapper, movie_mapper, user_inv_mapper, movie_inv_mapper = create_X(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our `X` matrix contains 610 users and 9724 movies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating sparsity\n",
    "\n",
    "Here, we calculate sparsity by dividing the number of stored elements by total number of elements. The number of stored (non-empty) elements in our matrix ([nnz](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.nnz.html)) is equivalent to the number of ratings in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_total = X.shape[0]*X.shape[1]\n",
    "n_ratings = X.nnz\n",
    "sparsity = n_ratings/n_total\n",
    "print(f\"Matrix sparsity: {round(sparsity*100,2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`csr_matrix.nnz` counts the stored values in our sparse matrix. The rest of our cells are empty.\n",
    "\n",
    "The **cold start problem** is when there are new users and movies in our matrix that do not have any ratings. In our Movielens dataset, all users and movies have at least one rating but in general, it's useful to check which users and movies have few interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_ratings_per_user = X.getnnz(axis=1)\n",
    "len(n_ratings_per_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Most active user rated {n_ratings_per_user.max()} movies.\")\n",
    "print(f\"Least active user rated {n_ratings_per_user.min()} movies.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_ratings_per_movie = X.getnnz(axis=0)\n",
    "len(n_ratings_per_movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Most rated movie has {n_ratings_per_movie.max()} ratings.\")\n",
    "print(f\"Least rated movie has {n_ratings_per_movie.min()} ratings.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,4))\n",
    "plt.subplot(1,2,1)\n",
    "sns.kdeplot(n_ratings_per_user, shade=True)\n",
    "plt.xlim(0)\n",
    "plt.title(\"Number of Ratings Per User\", fontsize=14)\n",
    "plt.xlabel(\"number of ratings per user\")\n",
    "plt.ylabel(\"density\")\n",
    "plt.subplot(1,2,2)\n",
    "sns.kdeplot(n_ratings_per_movie, shade=True)\n",
    "plt.xlim(0)\n",
    "plt.title(\"Number of Ratings Per Movie\", fontsize=14)\n",
    "plt.xlabel(\"number of ratings per movie\")\n",
    "plt.ylabel(\"density\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Item-item Recommendations with k-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to find the $k$ movies that have the most similar user engagement vectors for movie $i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "def find_similar_movies(movie_id, X, movie_mapper, movie_inv_mapper, k, metric='cosine'):\n",
    "    \"\"\"\n",
    "    Finds k-nearest neighbours for a given movie id.\n",
    "    \n",
    "    Args:\n",
    "        movie_id: id of the movie of interest\n",
    "        X: user-item utility matrix\n",
    "        k: number of similar movies to retrieve\n",
    "        metric: distance metric for kNN calculations\n",
    "    \n",
    "    Output: returns list of k similar movie ID's\n",
    "    \"\"\"\n",
    "    X = X.T\n",
    "    neighbour_ids = []\n",
    "    \n",
    "    movie_ind = movie_mapper[movie_id]\n",
    "    movie_vec = X[movie_ind]\n",
    "    if isinstance(movie_vec, (np.ndarray)):\n",
    "        movie_vec = movie_vec.reshape(1,-1)\n",
    "    # use k+1 since kNN output includes the movieId of interest\n",
    "    kNN = NearestNeighbors(n_neighbors=k+1, algorithm=\"brute\", metric=metric)\n",
    "    kNN.fit(X)\n",
    "    neighbour = kNN.kneighbors(movie_vec, return_distance=False)\n",
    "    for i in range(0,k):\n",
    "        n = neighbour.item(i)\n",
    "        neighbour_ids.append(movie_inv_mapper[n])\n",
    "    neighbour_ids.pop(0)\n",
    "    return neighbour_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`find_similar_movies()` takes in a `movieId` and `X` matrix, and outputs a list of $k$ movies that are similar to the `movieId` of interest.\n",
    "\n",
    "Let's see how it works in action. We will first create another mapper that maps movieId to title so that our results are interpretable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_movies = find_similar_movies(1, X, movie_mapper, movie_inv_mapper, k=10)\n",
    "similar_movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`find_similar_movies()` returns a list of `movieId`'s that are most similar to your movie of interest. Let's convert these id's to titles so that we can interpret our results. To make things easier, we will create a dictionary that maps `movieId` to `title`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_titles = dict(zip(movies['movieId'], movies['title']))\n",
    "\n",
    "movie_id = 1\n",
    "\n",
    "similar_movies = find_similar_movies(movie_id, X, movie_mapper, movie_inv_mapper, metric='cosine', k=10)\n",
    "movie_title = movie_titles[movie_id]\n",
    "\n",
    "print(f\"Because you watched {movie_title}:\")\n",
    "for i in similar_movies:\n",
    "    print(movie_titles[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results above show the 10 movies that are most similar to Toy Story. Most movies in this list are family movies from the 1990s, which seems pretty reasonable. Note that these recommendations are based solely on user-item ratings. Movie features such as genres are not used in this approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also play around with the kNN distance metric and see what results you would get if you use \"manhattan\" or \"euclidean\" instead of \"cosine\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_id = 1\n",
    "\n",
    "similar_movies = find_similar_movies(movie_id, X, movie_mapper, movie_inv_mapper, metric='euclidean', k=10)\n",
    "movie_title = movie_titles[movie_id]\n",
    "\n",
    "print(f\"Because you watched {movie_title}:\")\n",
    "for i in similar_movies:\n",
    "    print(movie_titles[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Handling the cold-start problem\n",
    "\n",
    "Collaborative filtering relies solely on user-item interactions within the utility matrix. The issue with this approach is that brand new users or items with no iteractions get excluded from the recommendation system. This is called the **cold start problem**. Content-based filtering is a way to handle this problem by generating recommendations based on user and item features.\n",
    "\n",
    "First, we need to convert the `genres` column into binary features. Each genre will have its own column in the dataframe, and will be populated with 0 or 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_movies = movies['movieId'].nunique()\n",
    "print(f\"There are {n_movies} unique movies in our movies dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = set(g for G in movies['genres'] for g in G)\n",
    "\n",
    "for g in genres:\n",
    "    movies[g] = movies.genres.transform(lambda x: int(g in x))\n",
    "    \n",
    "movie_genres = movies.drop(columns=['movieId', 'title','genres'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_genres.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "cosine_sim = cosine_similarity(movie_genres, movie_genres)\n",
    "print(f\"Dimensions of our genres cosine similarity matrix: {cosine_sim.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, after passing the `movie_genres` dataframe into the cosine_similarity() function, we get a cosine similarity matrix of shape $(n_{\\text{movies}}, n_{\\text{movies}})$.\n",
    "\n",
    "This matrix is populated with values between 0 and 1 which represent the degree of similarity between movies along the x and y axes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a movie finder function\n",
    "Let's say we want to get recommendations for movies that are similar to Jumanji. To get results from our recommender, we need to know the exact title of a movie in our dataset.\n",
    "\n",
    "In our dataset, Jumanji is actually listed as 'Jumanji (1995)'. If we misspell Jumanji or forget to include its year of release, our recommender won't be able to identify which movie we're interested in.\n",
    "\n",
    "To make our recommender more user-friendly, we can use a Python package called [fuzzywuzzy](https://pypi.org/project/fuzzywuzzy/) which will find the most similar title to a string that you pass in. Let's create a function called `movie_finder()` which take advantage of fuzzywuzzy's string matching algorithm to get the most similar title to a user-inputted string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import process\n",
    "\n",
    "def movie_finder(title):\n",
    "    all_titles = movies['title'].tolist()\n",
    "    closest_match = process.extractOne(title,all_titles)\n",
    "    return closest_match[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test this out with our Jumanji example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jumanji (1995)'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = movie_finder('juminji')\n",
    "title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get relevant recommendations for `Jumanji`, we need to find its index in the cosine simialrity matrix. To identify which row we should be looking at, we can create a movie index mapper which maps a movie title to the index that it represents in our matrix.\n",
    "\n",
    "Let's create a movie index dictionary called `movie_idx` where the keys are movie titles and values are movie indices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_idx = dict(zip(movies['title'], list(movies.index)))\n",
    "idx = movie_idx[title]\n",
    "print(f\"Movie index for Jumanji: {idx}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this handy `movie_idx` dictionary, we know that Jumanji is represented by index 1 in our matrix. Let's get the top 10 most similar movies to Jumanji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_recommendations=10\n",
    "sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "sim_scores = sim_scores[1:(n_recommendations+1)]\n",
    "similar_movies = [i[0] for i in sim_scores]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`similar_movies` is an array of indices that represents Jumanji's top 10 recommendations. We can get the corresponding movie titles by either creating an inverse movie_idx mapper or using iloc on the title column of the movies dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Because you watched {title}:\")\n",
    "movies['title'].iloc[similar_movies]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool! These recommendations seem pretty relevant and similar to Jumanji. The first 5 movies are family-friendly films from the 90s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can test our recommender further with other movie titles. For your convenience, let's package the steps into a single function which takes in the movie title of interest and number of recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_content_based_recommendations(title_string, n_recommendations=10):\n",
    "    title = movie_finder(title_string)\n",
    "    idx = movie_idx[title]\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:(n_recommendations+1)]\n",
    "    similar_movies = [i[0] for i in sim_scores]\n",
    "    print(f\"Because you watched {title}:\")\n",
    "    print(movies['title'].iloc[similar_movies])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Because you watched Avatar (2009):\n",
      "5260                           Spider-Man 2 (2004)\n",
      "6238                       Superman Returns (2006)\n",
      "7018                              Star Trek (2009)\n",
      "7064    Transformers: Revenge of the Fallen (2009)\n",
      "7212                                 Avatar (2009)\n",
      "Name: title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "get_content_based_recommendations('Avatar', 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Dimensionality Reduction with Matrix Factorization (advanced)\n",
    "\n",
    "Matrix factorization (MF) is a linear algebra technique that can help us discover latent features underlying the interactions between users and movies. These latent features give a more compact representation of user tastes and item descriptions. MF is particularly useful for very sparse data and can enhance the quality of recommendations. The algorithm works by factorizing the original user-item matrix into two factor matrices:\n",
    "\n",
    "- user-factor matrix (n_users, k)\n",
    "- item-factor matrix (k, n_items)\n",
    "\n",
    "We are reducing the dimensions of our original matrix into \"taste\" dimensions. We cannot interpret what each latent feature $k$ represents. However, we could imagine that one latent feature may represent users who like romantic comedies from the 1990s, while another latent feature may represent movies which are independent foreign language films.\n",
    "\n",
    "$$X_{mn}\\approx P_{mk}\\times Q_{nk}^T = \\hat{X} $$\n",
    "<img src=\"images/matrix_factorization.png\" width=\"50%\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "svd = TruncatedSVD(n_components=20, n_iter=10)\n",
    "Q = svd.fit_transform(X.T)\n",
    "Q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_id = 1\n",
    "similar_movies = find_similar_movies(movie_id, Q.T, movie_mapper, movie_inv_mapper, metric='cosine', k=10)\n",
    "movie_title = movie_titles[movie_id]\n",
    "\n",
    "print(f\"Because you watched {movie_title}:\")\n",
    "for i in similar_movies:\n",
    "    print(movie_titles[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results above are the most similar movies to Toy Story using kNN on our “compressed” movie-factor matrix. We reduced the dimensions down to n_components=20. We can think of each component representing a latent feature such as movie genre."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
